= Lab 6: Using AWS Controllers for Kubernetes on ROSA

== Learning objectives

By the end of this lab, you will be able to:

* Understand AWS Controllers for Kubernetes (ACK) architecture and benefits
* Install and configure ACK Operators from the OpenShift software catalog
* Create IAM trust policies and roles for ACK service account integration
* Deploy AWS resources (S3 buckets) directly from Kubernetes manifests using ACK
* Verify AWS resource creation through ACK Operators
* Implement GitOps patterns for AWS infrastructure provisioning

== Value proposition

*For field teams*: This lab demonstrates ROSA's unique advantage of managing AWS infrastructure directly from Kubernetes, enabling true infrastructure-as-code through GitOps workflows. This is a key differentiator for customers already invested in AWS services.

*Customer proof points*:

* *Infrastructure as Code*: Provision AWS resources using native Kubernetes manifests, eliminating the need for external infrastructure tooling
* *GitOps-native*: Manage AWS infrastructure through the same GitOps workflows as application deployments, improving consistency and reducing operational overhead
* *Reduced complexity*: Eliminate the gap between application teams and infrastructure teams by managing everything through Kubernetes
* *Cost optimization*: Use AWS managed services without running supporting infrastructure in-cluster, reducing compute costs

== Introduction

AWS Controllers for Kubernetes (ACK) lets you define and use AWS service resources directly from Red Hat OpenShift Service on AWS. With ACK, you can take advantage of AWS-managed services for your applications without needing to define resources outside of the cluster or run services that provide supporting capabilities such as databases or message queues within the cluster.

You can install various ACK Operators directly from the software catalog. This makes it easy to get started and use the Operators with your applications.

In this tutorial lets deploy the ACK S3 Operator. 

== Setting up Environment variables 

. Configure the following environment variables, changing the cluster name to suit your cluster:
+
[source,sh,role=execute]
----
export CLUSTER_NAME=$(oc get infrastructure cluster -o=jsonpath="{.status.apiServerURL}" | awk -F '.' '{print $2}')
export REGION=$(rosa describe cluster -c ${CLUSTER_NAME} --output json | jq -r .region.id)
export OIDC_ENDPOINT=$(oc get authentication.config.openshift.io cluster -o json | jq -r .spec.serviceAccountIssuer | sed  's|^https://||')
export AWS_ACCOUNT_ID=`aws sts get-caller-identity --query Account --output text`
export ACK_SERVICE=s3
export ACK_SERVICE_ACCOUNT=ack-${ACK_SERVICE}-controller
export POLICY_ARN=arn:aws:iam::aws:policy/AmazonS3FullAccess
export AWS_PAGER=""
export SCRATCH="/tmp/${CLUSTER_NAME}/ack"
mkdir -p ${SCRATCH}
----

. Ensure all fields output correctly before moving to the next section.
+
[source,sh,role=execute]
----
echo "Cluster: ${CLUSTER_NAME}, Region: ${REGION}, OIDC Endpoint: ${OIDC_ENDPOINT}, AWS Account ID: ${AWS_ACCOUNT_ID}"
----


== Preparing AWS account

. Create an AWS Identity Access Management (IAM) trust policy for the ACK Operator:
+
[source,sh,role=execute]
----
cat <<EOF > "${SCRATCH}/trust-policy.json"
{
 "Version": "2012-10-17",
 "Statement": [
 {
 "Effect": "Allow",
 "Condition": {
   "StringEquals" : {
     "${OIDC_ENDPOINT}:sub": "system:serviceaccount:ack-system:${ACK_SERVICE_ACCOUNT}"
   }
 },
 "Principal": {
   "Federated": "arn:aws:iam::$AWS_ACCOUNT_ID:oidc-provider/${OIDC_ENDPOINT}"
 },
 "Action": "sts:AssumeRoleWithWebIdentity"
 }
 ]
}
EOF
----

. Create an AWS IAM role for the ACK Operator to assume with the AmazonS3FullAccess policy attached.
+
[source,sh,role=execute]
----
ROLE_ARN=$(aws iam create-role --role-name "ack-${ACK_SERVICE}-controller" \
   --assume-role-policy-document "file://${SCRATCH}/trust-policy.json" \
   --query Role.Arn --output text)
echo $ROLE_ARN

aws iam attach-role-policy --role-name "ack-${ACK_SERVICE}-controller" \
     --policy-arn ${POLICY_ARN}
----

== Installing the ACK S3 Controller 

. Create a project to install the ACK S3 Operator into.
+
[source,sh,role=execute]
----
oc new-project ack-system
----

. Create a file with the ACK S3 Operator configuration
+
[source,sh,role=execute]
----
cat << EOF > "${SCRATCH}/config.txt"
ACK_ENABLE_DEVELOPMENT_LOGGING=true
ACK_LOG_LEVEL=debug
ACK_WATCH_NAMESPACE=
AWS_REGION=${REGION}
AWS_ENDPOINT_URL=
ACK_RESOURCE_TAGS=
ENABLE_LEADER_ELECTION=true
LEADER_ELECTION_NAMESPACE=
RECONCILE_DEFAULT_MAX_CONCURRENT_SYNCS=1
FEATURE_FLAGS=
FEATURE_GATES=
ENABLE_CARM=false
EOF
----

. Use the file from the previous step to create a ConfigMap.
+
[source,sh,role=execute]
----
oc -n ack-system create configmap \
  --from-env-file=${SCRATCH}/config.txt ack-${ACK_SERVICE}-user-config
----

. Install the ACK S3 Operator from the software catalog:
+
[source,sh,role=execute]
----
cat << EOF | oc apply -f -
apiVersion: operators.coreos.com/v1
kind: OperatorGroup
metadata:
  name: ack-${ACK_SERVICE}-controller
  namespace: ack-system
spec:
  upgradeStrategy: Default
---
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  name: ack-${ACK_SERVICE}-controller
  namespace: ack-system
spec:
  channel: alpha
  installPlanApproval: Automatic
  name: ack-${ACK_SERVICE}-controller
  source: community-operators
  sourceNamespace: openshift-marketplace
EOF
----

. Install the ACK S3 Operator from the software catalog:
+
[source,sh,role=execute]
----
sleep 30 && \
oc -n ack-system annotate serviceaccount ${ACK_SERVICE_ACCOUNT} \
  eks.amazonaws.com/role-arn=${ROLE_ARN} && \
  oc -n ack-system rollout restart deployment ack-${ACK_SERVICE}-controller
----

. Verify that the ACK S3 Operator is running .
+
[source,sh,role=execute]
----
oc -n ack-system get pods
----
+
.Sample Output
[source,text,options=nowrap]
----
NAME                                 READY   STATUS    RESTARTS   AGE
ack-s3-controller-585f6775db-s4lfz   1/1     Running   0          51s
----

== Validating the deployment.
. Deploy an S3 bucket resource
+
[source,sh,role=execute]
----
cat << EOF | oc apply -f -
apiVersion: s3.services.k8s.aws/v1alpha1
kind: Bucket
metadata:
   name: ${CLUSTER_NAME}-bucket
   namespace: ack-system
spec:
   name: ${CLUSTER_NAME}-bucket
EOF
----

. Verify the S3 bucket was created in AWS
+
[source,sh,role=execute]
----
aws s3 ls | grep ${CLUSTER_NAME}-bucket
----
+
.Sample Output
[source,text,options=nowrap]
----
2025-10-04 14:51:45 mrmc-test-maz-bucket
----

== Summary

Excellent work! You have successfully deployed and configured AWS Controllers for Kubernetes (ACK) on ROSA.

=== What you accomplished

In this lab, you:

* ✅ Installed the ACK S3 Operator from the OpenShift software catalog
* ✅ Created IAM trust policies for secure ACK service account integration
* ✅ Configured IAM roles with least-privilege AWS permissions
* ✅ Deployed AWS S3 buckets using native Kubernetes manifests
* ✅ Verified AWS resource creation through ACK automation

=== Key takeaways for customer conversations

* *Infrastructure as Code*: AWS resources managed through Kubernetes manifests, enabling GitOps workflows
* *No external tooling*: Eliminate Terraform, CloudFormation, or AWS CLI scripts for infrastructure provisioning
* *Unified platform*: Application and infrastructure teams use the same Kubernetes-native workflows
* *AWS service integration*: Direct access to 20+ AWS services (S3, RDS, DynamoDB, SQS, SNS, etc.) through ACK Operators

=== Next steps

In the next lab, you will implement Network Policies to secure pod-to-pod communication and enforce zero-trust networking patterns on ROSA.








